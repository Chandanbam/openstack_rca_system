name: OpenStack RCA System CI/CD Pipeline

on:
  push:
    branches: [ main, deploy ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.10'
  MLFLOW_EXPERIMENT_NAME: 'openstack_rca_system_staging'
  DOCKER_IMAGE: 'openstack-rca-system'
  ECS_CLUSTER: 'openstack-rca-cluster'
  ECS_SERVICE: 'openstack-rca-service'

jobs:
  setup-and-cache:
    name: Setup and Cache Dependencies
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential curl wget
        
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements-*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-test-
          ${{ runner.os }}-pip-
          
    - name: Install base dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-base.txt
        
    - name: Create shared artifacts directory
      run: |
        mkdir -p shared-artifacts/{models,logs,configs}
        
    - name: Upload shared artifacts
      uses: actions/upload-artifact@v4
      with:
        name: shared-dependencies
        path: |
          ~/.cache/pip
          shared-artifacts/
        retention-days: 1

  test-and-train:
    name: Test & Train Model
    needs: setup-and-cache
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Download shared dependencies
      uses: actions/download-artifact@v4
      with:
        name: shared-dependencies
        path: ~/.cache/pip
        
    - name: Install test dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
        pip install -r requirements-test.txt
        
    - name: Set up environment variables
      run: |
        echo "ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}" >> $GITHUB_ENV
        echo "MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }}" >> $GITHUB_ENV
        echo "MLFLOW_ARTIFACT_ROOT=${{ secrets.MLFLOW_ARTIFACT_ROOT }}" >> $GITHUB_ENV
        echo "MLFLOW_S3_ENDPOINT_URL=${{ secrets.MLFLOW_S3_ENDPOINT_URL }}" >> $GITHUB_ENV
        echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
        echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
        echo "AWS_DEFAULT_REGION=${{ secrets.AWS_DEFAULT_REGION }}" >> $GITHUB_ENV
        
    - name: Train model first
      run: |
        # Train the model
        python main.py --mode train --enable-mlflow --mlflow-experiment ${{ env.MLFLOW_EXPERIMENT_NAME }}
        
    - name: Run tests after training
      run: |
        # Run basic tests after training
        python -m pytest tests/test_artifacts.py -v --tb=short
        
    - name: Run RCA evaluation tests
      run: |
        # Run comprehensive RCA evaluation tests
        python -m pytest tests/test_rca_evaluation.py -v --tb=short
        
    - name: Run integration tests
      run: |
        # Run model performance tests
        python main.py --mode test-ml-model --custom-query "Database connection timeout" --iterations 2
        
    - name: Run RCA analysis tests
      run: |
        # Test RCA analysis functionality
        python main.py --mode analyze --issue "Nova service not responding" --fast-mode --enable-mlflow
        
    - name: Upload test artifacts (cached for reuse)
      uses: actions/upload-artifact@v4
      with:
        name: test-artifacts
        path: |
          coverage.xml
          htmlcov/
          models/
          logs/
          data/
        retention-days: 30
        
  mlflow-deploy:
    name: Deploy to MLflow & S3
    needs: test-and-train
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/deploy'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Download shared dependencies
      uses: actions/download-artifact@v4
      with:
        name: shared-dependencies
        path: ~/.cache/pip
        
    - name: Install MLflow dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-mlflow.txt
        pip install -r requirements-mlflow.txt
        
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_DEFAULT_REGION }}
        
    - name: Set up environment variables
      run: |
        echo "ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}" >> $GITHUB_ENV
        echo "MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }}" >> $GITHUB_ENV
        echo "MLFLOW_ARTIFACT_ROOT=${{ secrets.MLFLOW_ARTIFACT_ROOT }}" >> $GITHUB_ENV
        echo "MLFLOW_S3_ENDPOINT_URL=${{ secrets.MLFLOW_S3_ENDPOINT_URL }}" >> $GITHUB_ENV
        
    - name: Deploy model to MLflow & S3
      run: |
        # Train and deploy model with versioning
        python main.py --mode train --enable-mlflow --mlflow-experiment ${{ env.MLFLOW_EXPERIMENT_NAME }}
        
        # Verify model deployment
        python -c "
        from mlflow_integration.mlflow_manager import MLflowManager
        from config.config import Config
        
        mgr = MLflowManager(
            tracking_uri=Config.MLFLOW_TRACKING_URI,
            experiment_name='${{ env.MLFLOW_EXPERIMENT_NAME }}'
        )
        
        if mgr.is_enabled:
            model = mgr.load_model_with_versioning(model_name='lstm_model', version='latest')
            if model:
                print('âœ… Model successfully deployed to MLflow & S3')
            else:
                print('âŒ Model deployment verification failed')
                exit(1)
        else:
            print('âŒ MLflow not enabled')
            exit(1)
        "
        
    - name: Log deployment info
      run: |
        echo "ðŸš€ Model deployed to MLflow experiment: ${{ env.MLFLOW_EXPERIMENT_NAME }}"
        echo "ðŸ“¦ S3 location: ${{ secrets.MLFLOW_ARTIFACT_ROOT }}"
        echo "ðŸ”— MLflow URI: ${{ secrets.MLFLOW_TRACKING_URI }}"
        
    - name: Upload MLflow artifacts
      uses: actions/upload-artifact@v4
      with:
        name: mlflow-artifacts
        path: |
          models/
          logs/
          mlflow_integration/
        retention-days: 7
        
  docker-build:
    name: Build Docker Image
    needs: mlflow-deploy
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/deploy'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download MLflow artifacts
      uses: actions/download-artifact@v4
      with:
        name: mlflow-artifacts
        path: ./
        
    - name: Set up Python for utility scripts
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install minimal Python dependencies for Docker build
      run: |
        python -m pip install --upgrade pip
        pip install requests  # Only for utility scripts
        
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v4
      
    - name: Cache Docker layers
      uses: actions/cache@v4
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ github.sha }}
        restore-keys: |
          ${{ runner.os }}-buildx-
          
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_DEFAULT_REGION }}
        
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v4
      
    - name: Download MLflow artifacts
      uses: actions/download-artifact@v4
      with:
        name: mlflow-artifacts
        path: ./
        
    - name: Set up environment variables
      run: |
        echo "DOCKER_USERNAME=${{ secrets.DOCKER_USERNAME }}" >> $GITHUB_ENV
        echo "DOCKER_PASSWORD=${{ secrets.DOCKER_PASSWORD }}" >> $GITHUB_ENV
        echo "ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}" >> $GITHUB_ENV
        echo "MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }}" >> $GITHUB_ENV
        echo "MLFLOW_ARTIFACT_ROOT=${{ secrets.MLFLOW_ARTIFACT_ROOT }}" >> $GITHUB_ENV
        echo "MLFLOW_S3_ENDPOINT_URL=${{ secrets.MLFLOW_S3_ENDPOINT_URL }}" >> $GITHUB_ENV
        echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
        echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
        echo "AWS_DEFAULT_REGION=${{ secrets.AWS_DEFAULT_REGION }}" >> $GITHUB_ENV
        
    - name: Build and test Docker image
      run: |
        # Make build script executable
        chmod +x docker-build.sh
        
        # Build Docker image using our build script
        ./docker-build.sh
        
        # Test the built image
        docker run --rm -d --name test-container -p 8501:8501 \
          -e ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }} \
          -e MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }} \
          -e MLFLOW_ARTIFACT_ROOT=${{ secrets.MLFLOW_ARTIFACT_ROOT }} \
          -e MLFLOW_S3_ENDPOINT_URL=${{ secrets.MLFLOW_S3_ENDPOINT_URL }} \
          -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }} \
          -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }} \
          -e AWS_DEFAULT_REGION=${{ secrets.AWS_DEFAULT_REGION }} \
          -e CONTAINER_PORT=7051 \
          -e DEBUG=false \
          -e ENVIRONMENT=production \
          openstack-rca-system:latest
          
        # Wait for container to start
        sleep 30
        
        # Test health endpoint
        curl -f http://localhost:8501/_stcore/health || exit 1
        
        # Stop test container
        docker stop test-container
        
    - name: Login to Docker Hub
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
        
    - name: Push to Docker Hub
      run: |
        echo "ðŸ³ Pushing Docker image to Docker Hub..."
        
        # Tag the image with multiple tags
        docker tag openstack-rca-system:latest ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ github.sha }}
        docker tag openstack-rca-system:latest ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:latest
        
        # Push both tags
        docker push ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ github.sha }}
        docker push ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:latest
        
        echo "âœ… Successfully pushed to Docker Hub:"
        echo "   ðŸ“¦ ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ github.sha }}"
        echo "   ðŸ“¦ ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:latest"
        echo "ðŸ”— Image ready for ECS deployment"
        
    - name: Upload Docker artifacts
      uses: actions/upload-artifact@v4
      with:
        name: docker-artifacts
        path: |
          Dockerfile
          docker-compose.yml
          docker-build.sh
        retention-days: 30
        
  ecs-deploy:
    name: Deploy to AWS ECS (Placeholder)
    needs: docker-build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download Docker image info
      uses: actions/download-artifact@v4
      with:
        name: docker-image-info
        path: ./
        
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_DEFAULT_REGION }}
        
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      with:
        name: test-results
        path: ./test-results/
        
    - name: Download MLflow artifacts
      uses: actions/download-artifact@v4
      with:
        name: mlflow-artifacts
        path: ./mlflow-artifacts/
        
    - name: Download Docker artifacts
      uses: actions/download-artifact@v4
      with:
        name: docker-artifacts
        path: ./docker-artifacts/
        
    - name: ECS Deployment Placeholder
      run: |
        echo "ðŸš€ ECS Deployment Pipeline"
        echo "=========================="
        echo "ðŸ“‹ This step will deploy the container to AWS ECS"
        echo "ðŸ”§ Implementation will be added later"
        echo ""
        echo "ðŸ“Š Current status:"
        echo "âœ… Model trained and tested"
        echo "âœ… Model deployed to MLflow & S3"
        echo "âœ… Docker image built and tested"
        echo "â³ ECS deployment: Pending implementation"
        echo ""
        echo "ðŸŽ¯ Next steps:"
        echo "1. Create ECS cluster: ${{ env.ECS_CLUSTER }}"
        echo "2. Create ECS service: ${{ env.ECS_SERVICE }}"
        echo "3. Configure task definition"
        echo "4. Set up load balancer"
        echo "5. Configure auto-scaling"
        echo ""
        echo "ðŸ“ Manual deployment commands:"
        echo "aws ecs create-cluster --cluster-name ${{ env.ECS_CLUSTER }}"
        echo "aws ecs register-task-definition --cli-input-json file://task-definition.json"
        echo "aws ecs create-service --cluster ${{ env.ECS_CLUSTER }} --service-name ${{ env.ECS_SERVICE }} --task-definition openstack-rca-task"
        
    - name: Create deployment summary
      run: |
        echo "## ðŸš€ Deployment Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### âœ… Completed Steps:" >> $GITHUB_STEP_SUMMARY
        echo "- Model training and testing" >> $GITHUB_STEP_SUMMARY
        echo "- MLflow & S3 model deployment" >> $GITHUB_STEP_SUMMARY
        echo "- Docker image build and test" >> $GITHUB_STEP_SUMMARY
        echo "- Docker Hub push" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ”„ Pending Steps:" >> $GITHUB_STEP_SUMMARY
        echo "- ECS deployment (to be implemented)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“Š Artifacts:" >> $GITHUB_STEP_SUMMARY
        echo "- Model: ${{ secrets.MLFLOW_ARTIFACT_ROOT }}" >> $GITHUB_STEP_SUMMARY
        echo "- Docker Image: ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "- MLflow Experiment: ${{ env.MLFLOW_EXPERIMENT_NAME }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“¦ Shared Artifacts:" >> $GITHUB_STEP_SUMMARY
        echo "- Test Results: Available in test-results artifact" >> $GITHUB_STEP_SUMMARY
        echo "- MLflow Artifacts: Available in mlflow-artifacts artifact" >> $GITHUB_STEP_SUMMARY
        echo "- Docker Artifacts: Available in docker-artifacts artifact" >> $GITHUB_STEP_SUMMARY 
